{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.367856Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.368286Z\",\"iopub.status.idle\":\"2025-04-11T22:04:21.377977Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.368252Z\",\"shell.execute_reply\":\"2025-04-11T22:04:21.376846Z\"}}\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:19:41.351305Z\",\"iopub.execute_input\":\"2025-04-11T22:19:41.351737Z\",\"iopub.status.idle\":\"2025-04-11T22:19:41.356429Z\",\"shell.execute_reply.started\":\"2025-04-11T22:19:41.351703Z\",\"shell.execute_reply\":\"2025-04-11T22:19:41.355262Z\"}}\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.407596Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.407968Z\",\"iopub.status.idle\":\"2025-04-11T22:04:21.448788Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.407936Z\",\"shell.execute_reply\":\"2025-04-11T22:04:21.447637Z\"}}\ntrain_data=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest_data=pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n\nprint('setup complete')\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.450192Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.450493Z\",\"iopub.status.idle\":\"2025-04-11T22:04:21.533136Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.450466Z\",\"shell.execute_reply\":\"2025-04-11T22:04:21.532018Z\"}}\ntrain_data.describe()\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.535045Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.535454Z\",\"iopub.status.idle\":\"2025-04-11T22:04:21.541719Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.535424Z\",\"shell.execute_reply\":\"2025-04-11T22:04:21.540719Z\"}}\n#ვნახოთ ყველა სვეტი რომ გავიგოთ რა არის ჩვენი target variable\ntrain_data.columns\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.542887Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.543285Z\",\"iopub.status.idle\":\"2025-04-11T22:04:21.563700Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.543246Z\",\"shell.execute_reply\":\"2025-04-11T22:04:21.562488Z\"}}\n#target variable\ny=train_data.SalePrice\ntrain_data=train_data.drop(['SalePrice','Id'],axis=1)\ntest_data=test_data.drop('Id',axis=1)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.564976Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.565349Z\",\"iopub.status.idle\":\"2025-04-11T22:04:21.586349Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.565309Z\",\"shell.execute_reply\":\"2025-04-11T22:04:21.585243Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n#გავყოთ data set რადგან მონაცემების დამუშავების შემდეგ გაგვიმარტივდეს მოდელების ვალიდაცია\nfrom sklearn.model_selection import train_test_split\n\nX_tr, X_val, y_tr, y_val = train_test_split(train_data, y, test_size=0.2, random_state=42)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.655161Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.655506Z\",\"iopub.status.idle\":\"2025-04-11T22:04:21.665199Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.655477Z\",\"shell.execute_reply\":\"2025-04-11T22:04:21.664139Z\"}}\n#train_data.info()\n#info გვეუბნება რომ ჩვენი მონაცემები შეიცავს float, int და object ტიპის სვეტებს\n\n#იმისთვის რომ მოვამზადოთ გასაწვრთნელი dataset გავაცალკევოთ რიცხვითი და ობიქეტის ტიპის მონაცემები\nX_tr_numeric=X_tr.select_dtypes(include=['float64','int64'])\nX_tr_object=X_tr.select_dtypes(include=['object'])\n\nX_val_numeric=X_val.select_dtypes(include=['float64','int64'])\nX_val_object=X_val.select_dtypes(include=['object'])\n\ntest_data_numeric=test_data.select_dtypes(include=['float64','int64'])\ntest_data_object=test_data.select_dtypes(include=['object'])\n\n# %% [markdown]\n# # **Data Cleaning**\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.666977Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.667428Z\",\"iopub.status.idle\":\"2025-04-11T22:04:21.744184Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.667385Z\",\"shell.execute_reply\":\"2025-04-11T22:04:21.742983Z\"}}\n#გადავაგდოთ ისეთი სვეტები სადაც ძალიან დიდი ინფორმაცია დაკარგულია\ndef drop_missing(train_data):\n    cols_with_missing = [col for col in train_data.columns\n                         if train_data[col].isnull().any()]\n    \n    to_remove=[]\n    for col in cols_with_missing:\n        null_percentile=(train_data[col].isnull().mean())*100\n        if null_percentile>80: to_remove.append(col)\n    train_data=train_data.drop(to_remove,axis=1)\n    print('Dropping: ',to_remove)\n    return train_data\n\nX_tr_numeric=drop_missing(X_tr_numeric)\nX_tr_object=drop_missing(X_tr_object)\n\nX_val_numeric=drop_missing(X_val_numeric)\nX_val_object=drop_missing(X_val_object)\n\ntest_data_numeric=drop_missing(test_data_numeric)\ntest_data_object=drop_missing(test_data_object)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.746271Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.746574Z\",\"iopub.status.idle\":\"2025-04-11T22:04:21.906977Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.746544Z\",\"shell.execute_reply\":\"2025-04-11T22:04:21.905603Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n#შევავსოთ მონაცემებში დარჩენილი missing value-ები\ndef fill_in_gaps(train_data,dep,dependency=True):\n    for col in train_data.columns:\n        mode_val = train_data[col].mode()[0]\n        train_data.fillna({col:mode_val}, inplace=True)\n        if dependency:\n            dep.fillna({col:mode_val},inplace=True)\n    if dependency:\n        return train_data,dep\n    else:\n        return train_data,_\n\n\nX_tr_numeric,X_val_numeric=fill_in_gaps(X_tr_numeric,X_val_numeric)\nX_tr_object,X_val_object=fill_in_gaps(X_tr_object,X_val_object)\n\ntest_data_numeric,_=fill_in_gaps(test_data_numeric,_,False)\ntest_data_object,_=fill_in_gaps(test_data_object,_,False)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:21.908577Z\",\"iopub.execute_input\":\"2025-04-11T22:04:21.908943Z\",\"iopub.status.idle\":\"2025-04-11T22:04:22.149744Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:21.908915Z\",\"shell.execute_reply\":\"2025-04-11T22:04:22.148670Z\"}}\n#შევეცადოთ ძალიან ექსტრემალური მნიშვნელობების (outliers) მოშორება\nfrom scipy.stats.mstats import winsorize\ndef remove_outliers(train_data):\n    for col in train_data.columns:\n        train_data[col]=winsorize(train_data[col], limits=[0.01, 0.01])\n\n    return train_data\n\nX_tr_numeric=remove_outliers(X_tr_numeric)\nX_val_numeric=remove_outliers(X_val_numeric)\n\nX_tr_object=remove_outliers(X_tr_object)\nX_val_object=remove_outliers(X_val_object)\n\ntest_data_numeric=remove_outliers(test_data_numeric)\ntest_data_object=remove_outliers(test_data_object)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:22.150857Z\",\"iopub.execute_input\":\"2025-04-11T22:04:22.151244Z\",\"iopub.status.idle\":\"2025-04-11T22:04:22.255282Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:22.151207Z\",\"shell.execute_reply\":\"2025-04-11T22:04:22.254370Z\"}}\n#ამოვშალოთ ისეთი სვეტები სადაც მნიშვნელობები ძირითადად ერთნაირია\ndef remove_repeated(train_data,dep,dependency=True):\n    THRESHOLD = 0.97\n    cols_to_drop = []\n    for col in train_data.columns:\n        most_common_pct = train_data[col].value_counts(normalize=True).iloc[0]\n        \n        if most_common_pct >= THRESHOLD:\n            cols_to_drop.append(col)\n    print('Dropping columns: ',cols_to_drop)\n    train_data=train_data.drop(cols_to_drop,axis=1)\n    if dependency: \n        dep=dep.drop(cols_to_drop,axis=1)\n\n    if dependency: \n        return train_data,dep\n    else:\n        return train_data,None\n\nX_tr_numeric,X_val_numeric=remove_repeated(X_tr_numeric,X_val_numeric)\nX_tr_object,X_val_object=remove_repeated(X_tr_object,X_val_object)\n\ndummy=test_data_numeric.copy()\ntest_data_numeric,dummy=remove_repeated(test_data_numeric,dummy,False)\ntest_data_object,dummy=remove_repeated(test_data_object,dummy,False)\n\n# %% [markdown]\n# # **Feature Engineering**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:22.256262Z\",\"iopub.execute_input\":\"2025-04-11T22:04:22.256584Z\",\"iopub.status.idle\":\"2025-04-11T22:04:22.703318Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:22.256559Z\",\"shell.execute_reply\":\"2025-04-11T22:04:22.702011Z\"},\"jupyter\":{\"outputs_hidden\":false}}\n#დარჩენილ კატეგორიულ მონაცემებს გავუკეთოთ ენკოდირება\nfrom category_encoders.woe import WOEEncoder\n\nbinaryColumns = [col for col in X_tr_object.columns if X_tr_object[col].nunique() <= 2]\nnonBinaryColumns = [col for col in X_tr_object.columns if X_tr_object[col].nunique() > 2]\n\nmedian = y_tr.median()\ny_ch = (y_tr >= median).astype(int)\n\nwoe_encoder = WOEEncoder(cols=nonBinaryColumns)\nX_tr_object[nonBinaryColumns] = woe_encoder.fit_transform(X_tr_object[nonBinaryColumns], y_ch)\nX_val_object[nonBinaryColumns] = woe_encoder.transform(X_val_object[nonBinaryColumns])\ntest_data_object[nonBinaryColumns] = woe_encoder.transform(test_data_object[nonBinaryColumns])\n\nX_tr_ohe = pd.get_dummies(X_tr_object[binaryColumns], drop_first=True, dtype=int)\nX_val_ohe = pd.get_dummies(X_val_object[binaryColumns], drop_first=True, dtype=int)\nX_test_ohe = pd.get_dummies(test_data_object[binaryColumns], drop_first=True, dtype=int)\n\nmissing_cols_val = set(X_tr_ohe.columns) - set(X_val_ohe.columns)\nfor col in missing_cols_val:\n    X_val_ohe[col] = 0\nX_val_ohe = X_val_ohe[X_tr_ohe.columns]\n\nmissing_cols_test = set(X_tr_ohe.columns) - set(X_test_ohe.columns)\nfor col in missing_cols_test:\n    X_test_ohe[col] = 0\nX_test_ohe = X_test_ohe[X_tr_ohe.columns]\n\nX_tr_object = X_tr_object.drop(binaryColumns, axis=1)\nX_val_object = X_val_object.drop(binaryColumns, axis=1)\ntest_data_object = test_data_object.drop(binaryColumns, axis=1)\n\nX_tr_object = pd.concat([X_tr_object, X_tr_ohe], axis=1)\nX_val_object = pd.concat([X_val_object, X_val_ohe], axis=1)\ntest_data_object = pd.concat([test_data_object, X_test_ohe], axis=1)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:22.704474Z\",\"iopub.execute_input\":\"2025-04-11T22:04:22.704895Z\",\"iopub.status.idle\":\"2025-04-11T22:04:22.710052Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:22.704818Z\",\"shell.execute_reply\":\"2025-04-11T22:04:22.708780Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nassert len(X_tr_object.columns)==len(X_val_object.columns), 'Column quantities dont match'\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:22.713219Z\",\"iopub.execute_input\":\"2025-04-11T22:04:22.713529Z\",\"iopub.status.idle\":\"2025-04-11T22:04:22.787783Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:22.713502Z\",\"shell.execute_reply\":\"2025-04-11T22:04:22.786365Z\"}}\n#ახლა როცა ყველა მონაცემი რიცხვითია, დავთვალოთ სვეტებს შორის კორელაციები და მაღალი კორელაციის მქონე სვეტებიდან გადავაგდოთ ერთ-ერთი\ndef drop_correlated(X,dep,dependency=True):\n    corr_matrix_abs = X.corr().abs()\n    high_corr_pairs=set()\n    \n    for i in corr_matrix_abs.columns:\n        for j in corr_matrix_abs.columns:\n            if i < j and corr_matrix_abs.loc[i, j] >= 0.85:\n                    high_corr_pairs.add((i, j))\n    \n    high_corr_pairs = list(high_corr_pairs)\n    to_drop=[]\n    for col1,col2 in high_corr_pairs:to_drop.append(col1)\n    print(to_drop)\n    X=X.drop(to_drop,axis=1)\n    if dependency:\n        dep=dep.drop(to_drop,axis=1)\n    return X,dep\n\nX_tr_numeric,X_val_numeric=drop_correlated(X_tr_numeric,X_val_numeric)\nX_tr_object,X_val_object=drop_correlated(X_tr_object,X_val_object)\n\ntest_data_numeric,_=drop_correlated(test_data_numeric,_,False)\ntest_data_object,_=drop_correlated(test_data_object,_,False)\n\n# %% [markdown] {\"jupyter\":{\"outputs_hidden\":false}}\n# # **Training**\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:22.789897Z\",\"iopub.execute_input\":\"2025-04-11T22:04:22.790252Z\",\"iopub.status.idle\":\"2025-04-11T22:04:22.803947Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:22.790218Z\",\"shell.execute_reply\":\"2025-04-11T22:04:22.802903Z\"}}\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.linear_model import LinearRegression\n\n\nX_tr = pd.concat(\n    [X_tr_numeric, X_tr_object], \n    axis=1,\n    verify_integrity=True\n)\nX_val = pd.concat(\n    [X_val_numeric, X_val_object], \n    axis=1,\n    verify_integrity=True\n)\n\ntest_data = pd.concat(\n    [test_data_numeric, test_data_object], \n    axis=1,\n    verify_integrity=True\n)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:22.805072Z\",\"iopub.execute_input\":\"2025-04-11T22:04:22.805403Z\",\"iopub.status.idle\":\"2025-04-11T22:04:22.813146Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:22.805376Z\",\"shell.execute_reply\":\"2025-04-11T22:04:22.811902Z\"}}\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_val_score, KFold,GridSearchCV\nfrom sklearn.metrics import r2_score, mean_squared_log_error\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\n\nresults = {}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:22.814215Z\",\"iopub.execute_input\":\"2025-04-11T22:04:22.814513Z\",\"iopub.status.idle\":\"2025-04-11T22:04:22.891710Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:22.814481Z\",\"shell.execute_reply\":\"2025-04-11T22:04:22.890511Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"Testing Linear Regression...\")\nlr = LinearRegression()\nlr_scores = cross_val_score(lr, X_tr, y_tr, cv=kf, scoring='r2')\nresults['Linear'] = {\n    'CV R2 Mean': np.mean(lr_scores),\n    'CV R2 Std': np.std(lr_scores)\n}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:04:22.892813Z\",\"iopub.execute_input\":\"2025-04-11T22:04:22.893232Z\",\"iopub.status.idle\":\"2025-04-11T22:05:11.823276Z\",\"shell.execute_reply.started\":\"2025-04-11T22:04:22.893191Z\",\"shell.execute_reply\":\"2025-04-11T22:05:11.821705Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"Testing Random Forest...\")\nrf_params = {\n    'n_estimators': [100, 200],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [2, 5]\n}\nrf = RandomForestRegressor(random_state=42)\nrf_grid = GridSearchCV(rf, rf_params, cv=kf, scoring='r2', n_jobs=-1)\nrf_grid.fit(X_tr, y_tr)\nresults['RandomForest'] = {\n    'CV R2 Mean': rf_grid.best_score_,\n    'Best Params': rf_grid.best_params_\n}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:05:11.824870Z\",\"iopub.execute_input\":\"2025-04-11T22:05:11.825337Z\",\"iopub.status.idle\":\"2025-04-11T22:05:28.788735Z\",\"shell.execute_reply.started\":\"2025-04-11T22:05:11.825292Z\",\"shell.execute_reply\":\"2025-04-11T22:05:28.787752Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"Testing XGBoost...\")\nxgb_params = {\n    'n_estimators': [100, 200],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'max_depth': [3, 5],\n    'subsample': [0.8, 0.9]\n}\nxgb = XGBRegressor(random_state=42)\nxgb_grid = GridSearchCV(xgb, xgb_params, cv=kf, scoring='r2', n_jobs=-1)\nxgb_grid.fit(X_tr, y_tr)\nresults['XGBoost'] = {\n    'CV R2 Mean': xgb_grid.best_score_,\n    'Best Params': xgb_grid.best_params_\n}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:05:28.789917Z\",\"iopub.execute_input\":\"2025-04-11T22:05:28.790706Z\",\"iopub.status.idle\":\"2025-04-11T22:05:29.729412Z\",\"shell.execute_reply.started\":\"2025-04-11T22:05:28.790670Z\",\"shell.execute_reply\":\"2025-04-11T22:05:29.728334Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"Testing Lasso...\")\nlasso_params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\nlasso = Lasso(random_state=42)\nlasso_grid = GridSearchCV(lasso, lasso_params, cv=kf, scoring='r2', n_jobs=-1)\nlasso_grid.fit(X_tr, y_tr)\nresults['Lasso'] = {\n    'CV R2 Mean': lasso_grid.best_score_,\n    'Best Params': lasso_grid.best_params_\n}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:05:29.730488Z\",\"iopub.execute_input\":\"2025-04-11T22:05:29.730863Z\",\"iopub.status.idle\":\"2025-04-11T22:05:29.858776Z\",\"shell.execute_reply.started\":\"2025-04-11T22:05:29.730822Z\",\"shell.execute_reply\":\"2025-04-11T22:05:29.857899Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"Testing Ridge...\")\nridge_params = {'alpha': [0.1, 1, 10, 100, 1000]}\nridge = Ridge(random_state=42)\nridge_grid = GridSearchCV(ridge, ridge_params, cv=kf, scoring='r2', n_jobs=-1)\nridge_grid.fit(X_tr, y_tr)\nresults['Ridge'] = {\n    'CV R2 Mean': ridge_grid.best_score_,\n    'Best Params': ridge_grid.best_params_\n}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:05:29.859487Z\",\"iopub.execute_input\":\"2025-04-11T22:05:29.860032Z\",\"iopub.status.idle\":\"2025-04-11T22:05:29.867522Z\",\"shell.execute_reply.started\":\"2025-04-11T22:05:29.859990Z\",\"shell.execute_reply\":\"2025-04-11T22:05:29.866126Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nbest_models = {\n    'LinearRegression':lr,\n    'RandomForest': rf_grid.best_estimator_,\n    'XGBoost': xgb_grid.best_estimator_,\n    'Lasso': lasso_grid.best_estimator_,\n    'Ridge': ridge_grid.best_estimator_\n}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:05:29.868754Z\",\"iopub.execute_input\":\"2025-04-11T22:05:29.869148Z\",\"iopub.status.idle\":\"2025-04-11T22:05:33.714347Z\",\"shell.execute_reply.started\":\"2025-04-11T22:05:29.869107Z\",\"shell.execute_reply\":\"2025-04-11T22:05:33.713213Z\"},\"jupyter\":{\"outputs_hidden\":false}}\nprint(\"Validation on Best Models:\")\nfor name, model in best_models.items():\n    model.fit(X_tr, y_tr)\n    preds = model.predict(X_val)\n    r2 = r2_score(y_val, preds)\n    rmse = np.sqrt(mean_squared_log_error(y_val, preds))\n    print(f\"{name}:\")\n    print(f\"  Validation R2: {r2:.4f}\")\n    print(f\"  Validation RMSLE: {rmse:.2f}\")\n\n# %% [markdown] {\"jupyter\":{\"outputs_hidden\":false}}\n# **საუკეთესო მოდელად შეიძლება ჩაითვალოს XGBoost, თუმცა სხვა მოდელებსაც მისაღები შედეგები აქვთ**\n\n# %% [markdown]\n# # **ML Flow Tracking**\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:05:33.715383Z\",\"iopub.execute_input\":\"2025-04-11T22:05:33.715666Z\",\"iopub.status.idle\":\"2025-04-11T22:05:38.295166Z\",\"shell.execute_reply.started\":\"2025-04-11T22:05:33.715641Z\",\"shell.execute_reply\":\"2025-04-11T22:05:38.293881Z\"}}\n!pip install dagshub\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:05:38.296537Z\",\"iopub.execute_input\":\"2025-04-11T22:05:38.296929Z\",\"iopub.status.idle\":\"2025-04-11T22:05:38.495117Z\",\"shell.execute_reply.started\":\"2025-04-11T22:05:38.296898Z\",\"shell.execute_reply\":\"2025-04-11T22:05:38.493846Z\"}}\nimport dagshub\ndagshub.init(repo_owner='skara-21', repo_name='Assignment1_ARD', mlflow=True)\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:05:38.496219Z\",\"iopub.execute_input\":\"2025-04-11T22:05:38.496694Z\",\"iopub.status.idle\":\"2025-04-11T22:05:43.195740Z\",\"shell.execute_reply.started\":\"2025-04-11T22:05:38.496655Z\",\"shell.execute_reply\":\"2025-04-11T22:05:43.194439Z\"}}\n!pip install mlflow\n\n# %% [code] {\"jupyter\":{\"outputs_hidden\":false},\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:05:43.197192Z\",\"iopub.execute_input\":\"2025-04-11T22:05:43.197566Z\",\"iopub.status.idle\":\"2025-04-11T22:06:50.421019Z\",\"shell.execute_reply.started\":\"2025-04-11T22:05:43.197535Z\",\"shell.execute_reply\":\"2025-04-11T22:06:50.419888Z\"}}\nimport mlflow\nimport mlflow.sklearn\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score, mean_squared_log_error\nfrom scipy import stats\nfrom dagshub import dagshub_logger\nfrom mlflow.models.signature import infer_signature\n\nmlflow.set_tracking_uri('https://dagshub.com/skara-21/Assignment1_ARD.mlflow')\nmlflow.set_experiment(\"House_Price_Prediction_Enhanced\")\n\ndef adjusted_r2(r2, n, p):\n    return 1 - (1 - r2) * (n - 1) / (n - p - 1)\n\ndef calculate_f_statistic(r2, n, p):\n    return (r2 / p) / ((1 - r2) / (n - p - 1))\n\ndef create_input_example(X, n_samples=5):\n    if len(X) > n_samples:\n        sample = X.sample(n_samples, random_state=42)\n    else:\n        sample = X.copy()\n    return sample\n\ndef log_model_performance(model, X_tr, y_tr, X_val, y_val, name):\n    with mlflow.start_run(nested=True, run_name=name):\n        model.fit(X_tr, y_tr)\n\n        input_example = create_input_example(X_tr)\n        signature = infer_signature(X_tr, model.predict(X_tr))\n        \n        train_preds = model.predict(X_tr)\n        val_preds = model.predict(X_val)\n        \n        n = X_tr.shape[0]\n        p = X_tr.shape[1]\n        \n        train_r2 = r2_score(y_tr, train_preds)\n        train_adj_r2 = adjusted_r2(train_r2, n, p)\n        train_rmse = np.sqrt(mean_squared_error(y_tr, train_preds))\n        train_mae = mean_absolute_error(y_tr, train_preds)\n        train_msle = mean_squared_log_error(y_tr, train_preds)\n        \n        val_r2 = r2_score(y_val, val_preds)\n        val_adj_r2 = adjusted_r2(val_r2, len(y_val), p)\n        val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n        val_mae = mean_absolute_error(y_val, val_preds)\n        val_msle = mean_squared_log_error(y_val, val_preds)\n        \n        f_stat = None\n        if hasattr(model, 'coef_'):\n            f_stat = calculate_f_statistic(train_r2, n, p)\n            p_value = stats.f.sf(f_stat, p, n-p-1)\n        \n        cv_scores = None\n        if hasattr(model, 'best_score_'):\n            cv_scores = model.best_score_\n        \n        if hasattr(model, 'best_params_'):\n            mlflow.log_params(model.best_params_)\n        elif hasattr(model, 'get_params'):\n            mlflow.log_params(model.get_params())\n        \n        mlflow.log_metrics({\n            \"train_r2\": train_r2,\n            \"train_adj_r2\": train_adj_r2,\n            \"train_rmse\": train_rmse,\n            \"train_mae\": train_mae,\n            \"train_msle\": train_msle\n        })\n        \n        mlflow.log_metrics({\n            \"val_r2\": val_r2,\n            \"val_adj_r2\": val_adj_r2,\n            \"val_rmse\": val_rmse,\n            \"val_mae\": val_mae,\n            \"val_msle\": val_msle\n        })\n        \n        if f_stat is not None:\n            mlflow.log_metrics({\n                \"f_statistic\": f_stat,\n                \"f_p_value\": p_value\n            })\n        \n        if cv_scores is not None:\n            mlflow.log_metrics({\n                \"cv_mean_score\": cv_scores\n            })\n        \n        mlflow.sklearn.log_model(\n            sk_model=model,\n            artifact_path=name,\n            signature=signature,\n            input_example=input_example\n        )\n        \n        print(f\"{name}\")\n        print(f\"Training R2: {train_r2:.4f}\")\n        print(f\"Validation R2: {val_r2:.4f}\")\n        print(f\"Validation RMSE: {val_rmse:.4f}\")\n        print(f\"MAE: {val_mae:.4f}\")\n        print(f\"MSLE: {val_msle:.4f}\")\n        if f_stat:\n            print(f\"F-statistic: {f_stat:.2f}\")\n            print(f\"p-value: {p_value:.4f}\")\n        if cv_scores:\n            print(f\"CV Mean Score: {cv_scores:.4f}\")\n\nwith dagshub_logger() as logger:\n    logger.log_hyperparams({\n        \"train_shape\": X_tr.shape,\n        \"validation_shape\": X_val.shape,\n        \"n_features\": X_tr.shape[1]\n    })\n    \n    for name, model in best_models.items():\n        log_model_performance(model, X_tr, y_tr, X_val, y_val, name)\n\n\n# %% [markdown]\n# # **Result saving**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:11:43.516879Z\",\"iopub.execute_input\":\"2025-04-11T22:11:43.517283Z\",\"iopub.status.idle\":\"2025-04-11T22:11:43.623545Z\",\"shell.execute_reply.started\":\"2025-04-11T22:11:43.517250Z\",\"shell.execute_reply\":\"2025-04-11T22:11:43.622610Z\"}}\ntest_data.to_csv('/kaggle/working/processed_test_data.csv', index=False)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-04-11T22:19:47.169067Z\",\"iopub.execute_input\":\"2025-04-11T22:19:47.169415Z\",\"iopub.status.idle\":\"2025-04-11T22:19:54.704579Z\",\"shell.execute_reply.started\":\"2025-04-11T22:19:47.169388Z\",\"shell.execute_reply\":\"2025-04-11T22:19:54.703511Z\"}}\nmlflow.start_run()\n\nmlflow.log_param(\"Logistic\", \"XGBoost\")\nmlflow.log_metric(\"Accuracy\", 0.91)\nmlflow.sklearn.log_model(\n    sk_model=best_models['XGBoost'],\n    artifact_path=\"models\",\n    registered_model_name=\"BestModel\"\n)\n\nmlflow.end_run()","metadata":{"_uuid":"7f03be0f-a1bd-4fd7-b459-cb8c417aa6b0","_cell_guid":"5027defd-5d42-4d7a-b225-8d24bc7a8f32","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}